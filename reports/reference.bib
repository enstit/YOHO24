@article{Venkatesh_2022,
   title={You Only Hear Once: A YOLO-like Algorithm for Audio Segmentation and Sound Event Detection},
   volume={12},
   ISSN={2076-3417},
   url={http://dx.doi.org/10.3390/app12073293},
   DOI={10.3390/app12073293},
   number={7},
   journal={Applied Sciences},
   publisher={MDPI AG},
   author={Venkatesh, Satvik and Moffat, David and Miranda, Eduardo Reck},
   year={2022},
   month=mar, pages={3293} }
 
@Article{app6060162,
AUTHOR = {Mesaros, Annamaria and Heittola, Toni and Virtanen, Tuomas},
TITLE = {Metrics for Polyphonic Sound Event Detection},
JOURNAL = {Applied Sciences},
VOLUME = {6},
YEAR = {2016},
NUMBER = {6},
ARTICLE-NUMBER = {162},
URL = {https://www.mdpi.com/2076-3417/6/6/162},
ISSN = {2076-3417},
ABSTRACT = {This paper presents and discusses various metrics proposed for evaluation of polyphonic sound event detection systems used in realistic situations where there are typically multiple sound sources active simultaneously. The system output in this case contains overlapping events, marked as multiple sounds detected as being active at the same time. The polyphonic system output requires a suitable procedure for evaluation against a reference. Metrics from neighboring fields such as speech recognition and speaker diarization can be used, but they need to be partially redefined to deal with the overlapping events. We present a review of the most common metrics in the field and the way they are adapted and interpreted in the polyphonic case. We discuss segment-based and event-based definitions of each metric and explain the consequences of instance-based and class-based averaging using a case study. In parallel, we provide a toolbox containing implementations of presented metrics.},
DOI = {10.3390/app6060162}
}