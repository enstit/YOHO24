{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOHO training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('./enstit/YOHO24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version:  2.1.2\n"
     ]
    }
   ],
   "source": [
    "# Import used libraries\n",
    "\n",
    "import pandas as pd\n",
    "print(\"Pandas version: \", pd.__version__)\n",
    "\n",
    "from utils import AudioFile, YOHODataset, YOHODataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_0:  tensor([[[-0.0329,  0.4425,  0.5799,  ...,  1.3928, -0.0962, -0.2009],\n",
      "         [-0.0348,  0.4374,  0.5723,  ...,  1.3889, -0.0655, -0.2012],\n",
      "         [-0.0381,  0.4289,  0.5596,  ...,  1.3824, -0.0217, -0.2018],\n",
      "         ...,\n",
      "         [-1.1914, -1.4997, -1.3121,  ..., -1.9538, -1.2554, -2.2680],\n",
      "         [-1.2754, -1.5072, -1.2038,  ..., -1.7031, -1.2814, -2.9766],\n",
      "         [-1.3882, -1.6844, -1.2313,  ..., -1.4122, -1.3381, -2.5239]]])\n",
      "y_0:  [('noise', 0, 10.0), ('jackhammer', 3.1254216166103967, 4.081540068079489), ('dog_bark', 4.272822510637965, 5.995148792556066), ('drilling', 4.644565713394142, 7.674565713394141)]\n"
     ]
    }
   ],
   "source": [
    "urbansed_df = YOHODataset(annotations_file='./data/urbansed.csv')\n",
    "\n",
    "print(\"x_0: \", urbansed_df[0][0])\n",
    "print(\"y_0: \", urbansed_df[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = YOHODataGenerator(urbansed_df, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.4250,  0.0163,  0.1438,  ...,  0.7634, -0.8801, -0.0325],\n",
       "           [-0.4269,  0.0116,  0.1367,  ...,  0.7594, -0.7385, -0.0333],\n",
       "           [-0.4299,  0.0037,  0.1250,  ...,  0.7528, -0.5955, -0.0345],\n",
       "           ...,\n",
       "           [-1.5006, -1.7868, -1.6126,  ..., -2.1995, -1.3379, -2.2418],\n",
       "           [-1.5786, -1.7937, -1.5121,  ..., -1.7472, -1.3332, -2.5059],\n",
       "           [-1.6833, -1.9583, -1.5377,  ..., -1.4409, -1.3837, -2.7651]]]]),\n",
       " [[('noise',), tensor([0]), tensor([10.], dtype=torch.float64)],\n",
       "  [('children_playing',),\n",
       "   tensor([1.9704], dtype=torch.float64),\n",
       "   tensor([5.8421], dtype=torch.float64)],\n",
       "  [('street_music',),\n",
       "   tensor([5.4357], dtype=torch.float64),\n",
       "   tensor([8.1999], dtype=torch.float64)],\n",
       "  [('drilling',),\n",
       "   tensor([6.8797], dtype=torch.float64),\n",
       "   tensor([10.4851], dtype=torch.float64)]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "train_features, train_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
