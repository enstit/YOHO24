%!TEX TS-program = pdflatex
%!TEX root = ../main.tex
%!TEX encoding = UTF-8 Unicode


\section[Introduction]{Introduction}

	\begin{frame}{Contents}
			
		\tableofcontents
		
		\note{
			\dots			
		}		
		
	\end{frame}
	
	\begin{frame}{Audio Segmentation and Sound Event Detection}
	
		The goal of automatic sound event detection (SED) methods is to recognize what is happening in an audio signal and when it is happening\footcite{Mesaros2021SoundED}.
		In practice, the goal is to recognize at what temporal instances different sounds are active within an audio signal.
		An example of sound event detection is presented below.
	
		\begin{figure}
			\centering
			\begin{tikzpicture}[samples=200, domain=0:5*360]
			
				\draw[draw=red,fill=red,fill opacity=0.2] (1,0) rectangle ++(4,2.25);
				\draw[draw=blue,fill=blue,fill opacity=0.2] (4,0) rectangle ++(2,2.25);
				\draw[draw=green,fill=green,fill opacity=0.2] (6.2,0) rectangle ++(1.5,2.25);

        		\begin{axis}[
            		width=10cm, height=4cm,
            		enlarge x limits=false,
            		hide x axis,
            		hide y axis
        		]
        			\addplot [no markers, smooth] {sin(x)+rand*2};
        		\end{axis}
    		\end{tikzpicture}
			\caption{Event Detection in an audio track.}
			\label{fig:sounddetection}
		\end{figure}
		
	\end{frame}
	
	\begin{frame}{Datasets}
	
		Common datasets for Audio Segmentation and Sound Event Detection problems are:
		
		\begin{itemize}
			\item \textbf{TUT Sound Event Detection}: primarily consists of street recordings with traffic and other activity, with audio examples of \SI{2.56}{\second} and a total size of approximately \SI{1.5}{\hour}. It has six unique audio classes -- Brakes Squeaking, Car, Children, Large Vehicle, People Speaking, and People Walking;
			\item \textbf{Urban-SED}: purely synthetic dataset, with audio example of \SI{10}{\second} and a total size of about \SI{30}{\hour}. It has ten unique audio classes -- Air Conditioner, Car Horn, Children Playing, Dog Bark, Drilling, Engine Idling, Gun Shot, Jackhammer, Siren, and Street Music.
		\end{itemize}
		
		The first dataset is too small to train a Neural Network model and requires use of augmentation techniques (we used \textbf{SpecAugment}\footcite{park19e_interspeech}).
	\end{frame}
	
	\begin{frame}{Metrics}
	
		A popular toolbox for Polyphonic Sound Event Detection models evaluation is \textbf{SED Eval}\footcite{app6060162}.
	
		\begin{multicols}{2}
  			\begin{equation*}
    			\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}
  			\end{equation*}\break
  			\begin{equation*}
    			\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}
  			\end{equation*}
		\end{multicols}

		$$
			\text{F$_{1}$-score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
		$$
	\end{frame}