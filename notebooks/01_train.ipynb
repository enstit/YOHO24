{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOHO training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version:  2.1.2\n"
     ]
    }
   ],
   "source": [
    "# Import used libraries\n",
    "\n",
    "import pandas as pd\n",
    "print(\"Pandas version: \", pd.__version__)\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from utils import AudioFile, YOHODataset, YOHODataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_0:  tensor([[[-0.0329,  0.4425,  0.5799,  ...,  1.3928, -0.0962, -0.2009],\n",
      "         [-0.0348,  0.4374,  0.5723,  ...,  1.3889, -0.0655, -0.2012],\n",
      "         [-0.0381,  0.4289,  0.5596,  ...,  1.3824, -0.0217, -0.2018],\n",
      "         ...,\n",
      "         [-1.1914, -1.4997, -1.3121,  ..., -1.9538, -1.2554, -2.2680],\n",
      "         [-1.2754, -1.5072, -1.2038,  ..., -1.7031, -1.2814, -2.9766],\n",
      "         [-1.3882, -1.6844, -1.2313,  ..., -1.4122, -1.3381, -2.5239]]])\n",
      "y_0:  [('noise', 0, 10.0), ('jackhammer', 3.1254216166103967, 4.081540068079489), ('dog_bark', 4.272822510637965, 5.995148792556066), ('drilling', 4.644565713394142, 7.674565713394141)]\n"
     ]
    }
   ],
   "source": [
    "urbansed_df = YOHODataset(\n",
    "    audios=[\n",
    "        AudioFile(filepath=file.filepath, labels=file.events)\n",
    "        for _, file in pd.read_csv(\"./data/urbansed.csv\").iterrows()\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"x_0: \", urbansed_df[0][0])\n",
    "print(\"y_0: \", urbansed_df[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 16001])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urbansed_df[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = YOHODataGenerator(urbansed_df, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.5202, -0.1274, -0.0139,  ...,  0.8030, -1.2471, -0.9547],\n",
       "           [-0.5218, -0.1316, -0.0202,  ...,  0.7998, -1.0589, -0.9574],\n",
       "           [-0.5245, -0.1386, -0.0306,  ...,  0.7945, -0.8947, -0.9616],\n",
       "           ...,\n",
       "           [-1.4776, -1.7323, -1.5773,  ..., -0.6732, -0.8195, -0.9068],\n",
       "           [-1.5470, -1.7385, -1.4878,  ..., -0.7840, -1.0408, -0.9202],\n",
       "           [-1.6402, -1.8850, -1.5106,  ..., -0.9398, -1.1218, -1.0222]]]]),\n",
       " [[('noise',), tensor([0]), tensor([10.], dtype=torch.float64)],\n",
       "  [('street_music',),\n",
       "   tensor([2.7464], dtype=torch.float64),\n",
       "   tensor([5.5726], dtype=torch.float64)],\n",
       "  [('jackhammer',),\n",
       "   tensor([3.5782], dtype=torch.float64),\n",
       "   tensor([5.9628], dtype=torch.float64)],\n",
       "  [('car_horn',),\n",
       "   tensor([4.8528], dtype=torch.float64),\n",
       "   tensor([7.6165], dtype=torch.float64)],\n",
       "  [('gun_shot',),\n",
       "   tensor([5.5970], dtype=torch.float64),\n",
       "   tensor([6.3242], dtype=torch.float64)],\n",
       "  [('jackhammer',),\n",
       "   tensor([6.0761], dtype=torch.float64),\n",
       "   tensor([7.6149], dtype=torch.float64)],\n",
       "  [('dog_bark',),\n",
       "   tensor([6.7109], dtype=torch.float64),\n",
       "   tensor([7.7328], dtype=torch.float64)],\n",
       "  [('siren',),\n",
       "   tensor([7.0854], dtype=torch.float64),\n",
       "   tensor([9.5607], dtype=torch.float64)],\n",
       "  [('gun_shot',),\n",
       "   tensor([7.2102], dtype=torch.float64),\n",
       "   tensor([9.6097], dtype=torch.float64)],\n",
       "  [('gun_shot',),\n",
       "   tensor([8.0367], dtype=torch.float64),\n",
       "   tensor([9.8067], dtype=torch.float64)]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "train_features, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.1787,  0.2099,  0.3221,  ...,  0.9875, -0.2363, -0.3157],\n",
       "           [-0.1803,  0.2057,  0.3159,  ...,  0.9843, -0.2106, -0.3160],\n",
       "           [-0.1829,  0.1988,  0.3056,  ...,  0.9791, -0.1743, -0.3164],\n",
       "           ...,\n",
       "           [-1.1256, -1.3775, -1.2242,  ..., -1.7420, -1.1733, -2.0069],\n",
       "           [-1.1942, -1.3836, -1.1357,  ..., -1.5353, -1.1901, -2.0069],\n",
       "           [-1.2864, -1.5285, -1.1582,  ..., -1.3005, -1.2324, -2.0069]]]]),\n",
       " [[('noise',), tensor([0]), tensor([10.], dtype=torch.float64)],\n",
       "  [('siren',),\n",
       "   tensor([2.1688], dtype=torch.float64),\n",
       "   tensor([3.7088], dtype=torch.float64)],\n",
       "  [('engine_idling',),\n",
       "   tensor([4.9572], dtype=torch.float64),\n",
       "   tensor([5.8155], dtype=torch.float64)],\n",
       "  [('engine_idling',),\n",
       "   tensor([5.1323], dtype=torch.float64),\n",
       "   tensor([6.3378], dtype=torch.float64)],\n",
       "  [('jackhammer',),\n",
       "   tensor([5.3999], dtype=torch.float64),\n",
       "   tensor([6.0277], dtype=torch.float64)],\n",
       "  [('street_music',),\n",
       "   tensor([9.2493], dtype=torch.float64),\n",
       "   tensor([9.8331], dtype=torch.float64)]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "train_features, train_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
